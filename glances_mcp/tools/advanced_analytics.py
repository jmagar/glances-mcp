"""Advanced analytics tools for Glances MCP server."""

from datetime import datetime
from typing import Any, Dict, List, Optional

from fastmcp import FastMCP

from config.validation import InputValidator
from glances_mcp.services.glances_client import GlancesClientPool
from glances_mcp.services.health_calculator import HealthCalculator
from glances_mcp.services.baseline_manager import BaselineManager
from glances_mcp.utils.helpers import safe_get
from glances_mcp.utils.logging import logger, performance_logger
from glances_mcp.utils.metrics import MetricsCalculator


def register_advanced_analytics_tools(
    app: FastMCP, 
    client_pool: GlancesClientPool,
    baseline_manager: BaselineManager
) -> None:
    """Register advanced analytics tools with the MCP server."""
    
    health_calculator = HealthCalculator()
    metrics_calculator = MetricsCalculator()
    
    @app.tool()
    async def generate_health_score(
        server_alias: Optional[str] = None,
        weights: Optional[Dict[str, float]] = None
    ) -> Dict[str, Any]:
        """Generate comprehensive health scores for servers."""
        start_time = datetime.now()
        
        try:
            clients = {}
            if server_alias:
                if server_alias not in client_pool.servers:
                    raise ValueError(f"Server '{server_alias}' not found")
                client = client_pool.get_client(server_alias)
                if client:
                    clients[server_alias] = client
            else:
                clients = client_pool.get_enabled_clients()
            
            health_scores = {}
            
            for alias, client in clients.items():
                try:
                    health_data = await health_calculator.calculate_server_health(
                        client, weights
                    )
                    health_scores[alias] = health_data
                
                except Exception as e:
                    logger.warning(
                        "Error calculating health score for server",
                        server_alias=alias,
                        error=str(e)
                    )
                    health_scores[alias] = {
                        "server_alias": alias,
                        "error": str(e),
                        "overall_score": 0.0,
                        "status": "error",
                        "timestamp": datetime.now().isoformat()
                    }
            
            # Calculate fleet-wide summary
            fleet_summary = _calculate_fleet_health_summary(health_scores)
            
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000
            performance_logger.log_tool_execution("generate_health_score", duration_ms, True)
            
            return {
                "servers": health_scores,
                "fleet_summary": fleet_summary
            }
        
        except Exception as e:
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000
            performance_logger.log_tool_execution("generate_health_score", duration_ms, False)
            logger.error("Error in generate_health_score", server_alias=server_alias, error=str(e))
            raise
    
    @app.tool()
    async def performance_comparison(
        server_alias: Optional[str] = None,
        baseline_hours: int = 24,
        metrics: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Compare current performance against historical baselines."""
        start_time = datetime.now()
        
        try:
            if metrics is None:
                metrics = ["cpu.total", "mem.percent", "load.min5"]
            
            clients = {}
            if server_alias:
                if server_alias not in client_pool.servers:
                    raise ValueError(f"Server '{server_alias}' not found")
                client = client_pool.get_client(server_alias)
                if client:
                    clients[server_alias] = client
            else:
                clients = client_pool.get_enabled_clients()
            
            comparison_results = {}\n            \n            for alias, client in clients.items():\n                try:\n                    # Get current metrics\n                    current_metrics = {}\n                    cpu_data = await client.get_cpu_info()\n                    memory_data = await client.get_memory_info()\n                    load_data = await client.get_load_average()\n                    \n                    current_metrics.update({\n                        \"cpu.total\": safe_get(cpu_data, \"total\", 0),\n                        \"mem.percent\": safe_get(memory_data, \"percent\", 0),\n                        \"load.min1\": safe_get(load_data, \"min1\", 0),\n                        \"load.min5\": safe_get(load_data, \"min5\", 0),\n                        \"load.min15\": safe_get(load_data, \"min15\", 0)\n                    })\n                    \n                    # Compare against baselines\n                    metric_comparisons = {}\n                    overall_status = \"normal\"\n                    deviations = []\n                    \n                    for metric in metrics:\n                        if metric in current_metrics:\n                            current_value = current_metrics[metric]\n                            \n                            # Get baseline comparison\n                            comparison = baseline_manager.compare_to_baseline(\n                                alias, metric, current_value\n                            )\n                            \n                            if comparison:\n                                metric_comparisons[metric] = comparison\n                                \n                                # Track overall status\n                                if comparison[\"status\"] == \"critical\":\n                                    overall_status = \"critical\"\n                                elif comparison[\"status\"] == \"warning\" and overall_status != \"critical\":\n                                    overall_status = \"warning\"\n                                \n                                # Track significant deviations\n                                if abs(comparison[\"z_score\"]) > 1.5:\n                                    deviations.append({\n                                        \"metric\": metric,\n                                        \"z_score\": comparison[\"z_score\"],\n                                        \"percent_change\": comparison[\"percent_change\"],\n                                        \"status\": comparison[\"status\"]\n                                    })\n                            else:\n                                metric_comparisons[metric] = {\n                                    \"status\": \"no_baseline\",\n                                    \"current_value\": current_value,\n                                    \"message\": \"No baseline available for comparison\"\n                                }\n                    \n                    # Get trend analysis\n                    trend_analysis = {}\n                    for metric in metrics:\n                        trend = baseline_manager.get_trend_analysis(alias, metric)\n                        if trend:\n                            trend_analysis[metric] = trend\n                    \n                    comparison_result = {\n                        \"server_alias\": alias,\n                        \"timestamp\": datetime.now().isoformat(),\n                        \"current_metrics\": current_metrics,\n                        \"baseline_comparison\": metric_comparisons,\n                        \"trend_analysis\": trend_analysis,\n                        \"overall_status\": overall_status,\n                        \"significant_deviations\": deviations,\n                        \"summary\": {\n                            \"metrics_compared\": len(metric_comparisons),\n                            \"metrics_with_baselines\": len([\n                                comp for comp in metric_comparisons.values()\n                                if comp.get(\"status\") != \"no_baseline\"\n                            ]),\n                            \"critical_metrics\": len([\n                                comp for comp in metric_comparisons.values()\n                                if comp.get(\"status\") == \"critical\"\n                            ]),\n                            \"warning_metrics\": len([\n                                comp for comp in metric_comparisons.values()\n                                if comp.get(\"status\") == \"warning\"\n                            ])\n                        }\n                    }\n                    \n                    comparison_results[alias] = comparison_result\n                \n                except Exception as e:\n                    logger.warning(\n                        \"Error in performance comparison for server\",\n                        server_alias=alias,\n                        error=str(e)\n                    )\n                    comparison_results[alias] = {\n                        \"server_alias\": alias,\n                        \"error\": str(e),\n                        \"timestamp\": datetime.now().isoformat()\n                    }\n            \n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"performance_comparison\", duration_ms, True)\n            \n            return {\"servers\": comparison_results}\n        \n        except Exception as e:\n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"performance_comparison\", duration_ms, False)\n            logger.error(\"Error in performance_comparison\", server_alias=server_alias, error=str(e))\n            raise\n    \n    @app.tool()\n    async def detect_anomalies(\n        server_alias: Optional[str] = None,\n        threshold_std: float = 2.0,\n        window_hours: int = 6\n    ) -> Dict[str, Any]:\n        \"\"\"Detect statistical anomalies in server metrics.\"\"\"\n        start_time = datetime.now()\n        \n        try:\n            clients = {}\n            if server_alias:\n                if server_alias not in client_pool.servers:\n                    raise ValueError(f\"Server '{server_alias}' not found\")\n                client = client_pool.get_client(server_alias)\n                if client:\n                    clients[server_alias] = client\n            else:\n                clients = client_pool.get_enabled_clients()\n            \n            anomaly_results = {}\n            \n            for alias, client in clients.items():\n                try:\n                    # Get recent data for anomaly detection\n                    anomalies_found = []\n                    \n                    # Check key metrics for anomalies\n                    metrics_to_check = [\"cpu.total\", \"mem.percent\", \"load.min5\"]\n                    \n                    for metric in metrics_to_check:\n                        # Get historical data from baseline manager\n                        buffer = baseline_manager._get_server_data_buffer(alias, metric)\n                        all_points = buffer.get_all()\n                        \n                        if len(all_points) > 10:  # Need sufficient data\n                            values = [p.value for p in all_points if hasattr(p, 'value')]\n                            \n                            # Detect anomalies\n                            anomalies = metrics_calculator.detect_anomalies(\n                                values, threshold_std\n                            )\n                            \n                            for idx, value, anomaly_type in anomalies:\n                                # Only report recent anomalies (last few samples)\n                                if idx >= len(values) - 5:\n                                    anomalies_found.append({\n                                        \"metric\": metric,\n                                        \"value\": value,\n                                        \"type\": anomaly_type,\n                                        \"index\": idx,\n                                        \"severity\": \"critical\" if abs(values[idx] - sum(values)/len(values)) > threshold_std * 2 else \"warning\"\n                                    })\n                    \n                    # Get current metrics for context\n                    current_metrics = {}\n                    try:\n                        cpu_data = await client.get_cpu_info()\n                        memory_data = await client.get_memory_info()\n                        load_data = await client.get_load_average()\n                        \n                        current_metrics.update({\n                            \"cpu.total\": safe_get(cpu_data, \"total\", 0),\n                            \"mem.percent\": safe_get(memory_data, \"percent\", 0),\n                            \"load.min5\": safe_get(load_data, \"min5\", 0)\n                        })\n                    except:\n                        pass\n                    \n                    anomaly_result = {\n                        \"server_alias\": alias,\n                        \"timestamp\": datetime.now().isoformat(),\n                        \"anomalies\": anomalies_found,\n                        \"current_metrics\": current_metrics,\n                        \"detection_params\": {\n                            \"threshold_std\": threshold_std,\n                            \"window_hours\": window_hours,\n                            \"metrics_checked\": metrics_to_check\n                        },\n                        \"summary\": {\n                            \"total_anomalies\": len(anomalies_found),\n                            \"critical_anomalies\": len([\n                                a for a in anomalies_found \n                                if a[\"severity\"] == \"critical\"\n                            ]),\n                            \"warning_anomalies\": len([\n                                a for a in anomalies_found \n                                if a[\"severity\"] == \"warning\"\n                            ]),\n                            \"has_recent_anomalies\": len(anomalies_found) > 0\n                        }\n                    }\n                    \n                    anomaly_results[alias] = anomaly_result\n                \n                except Exception as e:\n                    logger.warning(\n                        \"Error detecting anomalies for server\",\n                        server_alias=alias,\n                        error=str(e)\n                    )\n                    anomaly_results[alias] = {\n                        \"server_alias\": alias,\n                        \"error\": str(e),\n                        \"timestamp\": datetime.now().isoformat(),\n                        \"anomalies\": [],\n                        \"summary\": {\"total_anomalies\": 0, \"has_recent_anomalies\": False}\n                    }\n            \n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"detect_anomalies\", duration_ms, True)\n            \n            return {\"servers\": anomaly_results}\n        \n        except Exception as e:\n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"detect_anomalies\", duration_ms, False)\n            logger.error(\"Error in detect_anomalies\", server_alias=server_alias, error=str(e))\n            raise\n    \n    @app.tool()\n    async def capacity_analysis(\n        server_alias: Optional[str] = None,\n        projection_days: int = 30\n    ) -> Dict[str, Any]:\n        \"\"\"Analyze current capacity utilization and project future needs.\"\"\"\n        start_time = datetime.now()\n        \n        try:\n            clients = {}\n            if server_alias:\n                if server_alias not in client_pool.servers:\n                    raise ValueError(f\"Server '{server_alias}' not found\")\n                client = client_pool.get_client(server_alias)\n                if client:\n                    clients[server_alias] = client\n            else:\n                clients = client_pool.get_enabled_clients()\n            \n            capacity_results = {}\n            \n            for alias, client in clients.items():\n                try:\n                    # Get current utilization\n                    cpu_data = await client.get_cpu_info()\n                    memory_data = await client.get_memory_info()\n                    disk_data = await client.get_disk_usage()\n                    load_data = await client.get_load_average()\n                    system_data = await client.get_system_info()\n                    \n                    # Calculate current capacity utilization\n                    cpu_utilization = safe_get(cpu_data, \"total\", 0)\n                    memory_utilization = safe_get(memory_data, \"percent\", 0)\n                    \n                    # Find highest disk utilization\n                    disk_utilizations = [safe_get(disk, \"percent\", 0) for disk in disk_data]\n                    max_disk_utilization = max(disk_utilizations) if disk_utilizations else 0\n                    \n                    # Load utilization (normalized by CPU count)\n                    cpu_count = safe_get(system_data, \"cpucount\", 1)\n                    load_5min = safe_get(load_data, \"min5\", 0)\n                    load_utilization = min((load_5min / cpu_count) * 100, 200)  # Cap at 200%\n                    \n                    # Get trend data for projections\n                    cpu_trend = baseline_manager.get_trend_analysis(alias, \"cpu.total\", 24 * 7)  # 1 week\n                    memory_trend = baseline_manager.get_trend_analysis(alias, \"mem.percent\", 24 * 7)\n                    \n                    # Simple linear projection\n                    projections = {}\n                    \n                    if cpu_trend and cpu_trend[\"direction\"] == \"increasing\":\n                        days_to_80 = _calculate_days_to_threshold(\n                            cpu_utilization, 80, cpu_trend[\"recent_change\"], projection_days\n                        )\n                        days_to_90 = _calculate_days_to_threshold(\n                            cpu_utilization, 90, cpu_trend[\"recent_change\"], projection_days\n                        )\n                        projections[\"cpu\"] = {\n                            \"current\": cpu_utilization,\n                            \"trend_direction\": cpu_trend[\"direction\"],\n                            \"recent_change_percent\": cpu_trend[\"recent_change\"],\n                            \"days_to_80_percent\": days_to_80,\n                            \"days_to_90_percent\": days_to_90\n                        }\n                    \n                    if memory_trend and memory_trend[\"direction\"] == \"increasing\":\n                        days_to_80 = _calculate_days_to_threshold(\n                            memory_utilization, 80, memory_trend[\"recent_change\"], projection_days\n                        )\n                        days_to_90 = _calculate_days_to_threshold(\n                            memory_utilization, 90, memory_trend[\"recent_change\"], projection_days\n                        )\n                        projections[\"memory\"] = {\n                            \"current\": memory_utilization,\n                            \"trend_direction\": memory_trend[\"direction\"],\n                            \"recent_change_percent\": memory_trend[\"recent_change\"],\n                            \"days_to_80_percent\": days_to_80,\n                            \"days_to_90_percent\": days_to_90\n                        }\n                    \n                    # Capacity recommendations\n                    recommendations = []\n                    risk_level = \"low\"\n                    \n                    if cpu_utilization > 80:\n                        recommendations.append(\"CPU utilization is high - consider CPU upgrade\")\n                        risk_level = \"high\"\n                    elif cpu_utilization > 60:\n                        recommendations.append(\"CPU utilization is elevated - monitor closely\")\n                        if risk_level == \"low\":\n                            risk_level = \"medium\"\n                    \n                    if memory_utilization > 85:\n                        recommendations.append(\"Memory utilization is high - consider RAM upgrade\")\n                        risk_level = \"high\"\n                    elif memory_utilization > 70:\n                        recommendations.append(\"Memory utilization is elevated - monitor closely\")\n                        if risk_level == \"low\":\n                            risk_level = \"medium\"\n                    \n                    if max_disk_utilization > 90:\n                        recommendations.append(\"Disk space is critically low - immediate action required\")\n                        risk_level = \"high\"\n                    elif max_disk_utilization > 80:\n                        recommendations.append(\"Disk space is running low - plan for expansion\")\n                        if risk_level == \"low\":\n                            risk_level = \"medium\"\n                    \n                    if load_utilization > 150:\n                        recommendations.append(\"System load is very high - performance may be degraded\")\n                        risk_level = \"high\"\n                    \n                    capacity_result = {\n                        \"server_alias\": alias,\n                        \"timestamp\": datetime.now().isoformat(),\n                        \"current_utilization\": {\n                            \"cpu_percent\": cpu_utilization,\n                            \"memory_percent\": memory_utilization,\n                            \"disk_max_percent\": max_disk_utilization,\n                            \"load_normalized_percent\": load_utilization\n                        },\n                        \"projections\": projections,\n                        \"risk_assessment\": {\n                            \"level\": risk_level,\n                            \"recommendations\": recommendations,\n                            \"immediate_action_required\": risk_level == \"high\"\n                        },\n                        \"resource_details\": {\n                            \"cpu_count\": cpu_count,\n                            \"total_memory_gb\": safe_get(memory_data, \"total\", 0) / (1024**3),\n                            \"disk_count\": len(disk_data),\n                            \"highest_disk_usage\": {\n                                \"percent\": max_disk_utilization,\n                                \"mount_point\": next(\n                                    (disk[\"mnt_point\"] for disk in disk_data \n                                     if safe_get(disk, \"percent\", 0) == max_disk_utilization),\n                                    \"unknown\"\n                                ) if disk_data else \"unknown\"\n                            }\n                        }\n                    }\n                    \n                    capacity_results[alias] = capacity_result\n                \n                except Exception as e:\n                    logger.warning(\n                        \"Error in capacity analysis for server\",\n                        server_alias=alias,\n                        error=str(e)\n                    )\n                    capacity_results[alias] = {\n                        \"server_alias\": alias,\n                        \"error\": str(e),\n                        \"timestamp\": datetime.now().isoformat(),\n                        \"risk_assessment\": {\"level\": \"unknown\"}\n                    }\n            \n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"capacity_analysis\", duration_ms, True)\n            \n            return {\"servers\": capacity_results}\n        \n        except Exception as e:\n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"capacity_analysis\", duration_ms, False)\n            logger.error(\"Error in capacity_analysis\", server_alias=server_alias, error=str(e))\n            raise\n\n\ndef _calculate_fleet_health_summary(health_scores: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:\n    \"\"\"Calculate fleet-wide health summary.\"\"\"\n    if not health_scores:\n        return {\"total_servers\": 0}\n    \n    total_servers = len(health_scores)\n    healthy_servers = len([s for s in health_scores.values() if s.get(\"status\") == \"healthy\"])\n    warning_servers = len([s for s in health_scores.values() if s.get(\"status\") == \"warning\"])\n    critical_servers = len([s for s in health_scores.values() if s.get(\"status\") == \"critical\"])\n    error_servers = len([s for s in health_scores.values() if s.get(\"status\") == \"error\"])\n    \n    # Calculate average score\n    valid_scores = [s[\"overall_score\"] for s in health_scores.values() if isinstance(s.get(\"overall_score\"), (int, float))]\n    avg_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0\n    \n    # Determine fleet status\n    if critical_servers > 0 or error_servers > 0:\n        fleet_status = \"critical\"\n    elif warning_servers > total_servers * 0.3:  # More than 30% have warnings\n        fleet_status = \"warning\"\n    elif healthy_servers >= total_servers * 0.8:  # 80% or more are healthy\n        fleet_status = \"healthy\"\n    else:\n        fleet_status = \"degraded\"\n    \n    return {\n        \"total_servers\": total_servers,\n        \"healthy_servers\": healthy_servers,\n        \"warning_servers\": warning_servers,\n        \"critical_servers\": critical_servers,\n        \"error_servers\": error_servers,\n        \"fleet_status\": fleet_status,\n        \"average_score\": round(avg_score, 2),\n        \"health_percentage\": round((healthy_servers / total_servers) * 100, 1) if total_servers > 0 else 0\n    }\n\n\ndef _calculate_days_to_threshold(\n    current_value: float,\n    threshold: float,\n    daily_change_percent: float,\n    max_days: int\n) -> Optional[int]:\n    \"\"\"Calculate days until a metric reaches a threshold based on trend.\"\"\"\n    if daily_change_percent <= 0 or current_value >= threshold:\n        return None\n    \n    # Convert weekly change to daily change\n    daily_change = daily_change_percent / 7\n    \n    if daily_change == 0:\n        return None\n    \n    # Calculate days to reach threshold\n    days_needed = (threshold - current_value) / (current_value * daily_change / 100)\n    \n    return int(days_needed) if 0 < days_needed <= max_days else None