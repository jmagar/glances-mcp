"""Capacity planning tools for Glances MCP server."""

from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

from fastmcp import FastMCP

from config.models import GlancesServer
from glances_mcp.services.glances_client import GlancesClientPool
from glances_mcp.services.baseline_manager import BaselineManager
from glances_mcp.utils.helpers import format_bytes, safe_get
from glances_mcp.utils.logging import logger, performance_logger


def register_capacity_planning_tools(
    app: FastMCP,
    client_pool: GlancesClientPool,
    baseline_manager: BaselineManager
) -> None:
    """Register capacity planning tools with the MCP server."""
    
    @app.tool()
    async def predict_resource_needs(
        server_alias: Optional[str] = None,
        projection_days: int = 90,
        confidence_level: float = 0.80
    ) -> Dict[str, Any]:
        """Predict future resource needs based on historical trends and growth patterns."""
        start_time = datetime.now()
        
        try:\n            if projection_days < 1 or projection_days > 365:\n                raise ValueError(\"projection_days must be between 1 and 365\")\n            \n            if confidence_level < 0.5 or confidence_level > 0.99:\n                raise ValueError(\"confidence_level must be between 0.5 and 0.99\")\n            \n            clients = {}\n            if server_alias:\n                if server_alias not in client_pool.servers:\n                    raise ValueError(f\"Server '{server_alias}' not found\")\n                client = client_pool.get_client(server_alias)\n                if client:\n                    clients[server_alias] = client\n            else:\n                clients = client_pool.get_enabled_clients()\n            \n            predictions = {}\n            \n            for alias, client in clients.items():\n                try:\n                    # Get current resource utilization\n                    cpu_data = await client.get_cpu_info()\n                    memory_data = await client.get_memory_info()\n                    disk_data = await client.get_disk_usage()\n                    load_data = await client.get_load_average()\n                    system_data = await client.get_system_info()\n                    \n                    current_utilization = {\n                        \"cpu_percent\": safe_get(cpu_data, \"total\", 0),\n                        \"memory_percent\": safe_get(memory_data, \"percent\", 0),\n                        \"memory_total_gb\": safe_get(memory_data, \"total\", 0) / (1024**3),\n                        \"memory_used_gb\": safe_get(memory_data, \"used\", 0) / (1024**3),\n                        \"load_avg\": safe_get(load_data, \"min5\", 0),\n                        \"cpu_count\": safe_get(system_data, \"cpucount\", 1)\n                    }\n                    \n                    # Get trend analysis for prediction\n                    cpu_trend = baseline_manager.get_trend_analysis(alias, \"cpu.total\", 24 * 7)  # 1 week\n                    memory_trend = baseline_manager.get_trend_analysis(alias, \"mem.percent\", 24 * 7)\n                    load_trend = baseline_manager.get_trend_analysis(alias, \"load.min5\", 24 * 7)\n                    \n                    # Calculate predictions\n                    resource_predictions = {}\n                    \n                    # CPU prediction\n                    if cpu_trend and cpu_trend[\"confidence\"] >= confidence_level:\n                        cpu_prediction = _predict_resource_growth(\n                            current_utilization[\"cpu_percent\"],\n                            cpu_trend[\"recent_change\"],\n                            projection_days,\n                            \"cpu_percent\"\n                        )\n                        cpu_prediction[\"trend_confidence\"] = cpu_trend[\"confidence\"]\n                        resource_predictions[\"cpu\"] = cpu_prediction\n                    \n                    # Memory prediction\n                    if memory_trend and memory_trend[\"confidence\"] >= confidence_level:\n                        memory_prediction = _predict_resource_growth(\n                            current_utilization[\"memory_percent\"],\n                            memory_trend[\"recent_change\"],\n                            projection_days,\n                            \"memory_percent\"\n                        )\n                        memory_prediction[\"trend_confidence\"] = memory_trend[\"confidence\"]\n                        \n                        # Calculate absolute memory predictions\n                        current_memory_gb = current_utilization[\"memory_used_gb\"]\n                        total_memory_gb = current_utilization[\"memory_total_gb\"]\n                        \n                        predicted_memory_percent = memory_prediction[\"predicted_value\"]\n                        predicted_memory_gb = (predicted_memory_percent / 100) * total_memory_gb\n                        \n                        memory_prediction[\"predicted_memory_gb\"] = predicted_memory_gb\n                        memory_prediction[\"memory_growth_gb\"] = predicted_memory_gb - current_memory_gb\n                        memory_prediction[\"total_memory_gb\"] = total_memory_gb\n                        \n                        resource_predictions[\"memory\"] = memory_prediction\n                    \n                    # Load prediction\n                    if load_trend and load_trend[\"confidence\"] >= confidence_level:\n                        load_prediction = _predict_resource_growth(\n                            current_utilization[\"load_avg\"],\n                            load_trend[\"recent_change\"],\n                            projection_days,\n                            \"load_average\"\n                        )\n                        load_prediction[\"trend_confidence\"] = load_trend[\"confidence\"]\n                        load_prediction[\"cpu_count\"] = current_utilization[\"cpu_count\"]\n                        load_prediction[\"normalized_current\"] = current_utilization[\"load_avg\"] / current_utilization[\"cpu_count\"]\n                        load_prediction[\"normalized_predicted\"] = load_prediction[\"predicted_value\"] / current_utilization[\"cpu_count\"]\n                        \n                        resource_predictions[\"load\"] = load_prediction\n                    \n                    # Disk space prediction (for major filesystems)\n                    disk_predictions = []\n                    for disk in disk_data:\n                        if safe_get(disk, \"mnt_point\") in [\"/\", \"/home\", \"/var\", \"/opt\"]:\n                            disk_usage_percent = safe_get(disk, \"percent\", 0)\n                            \n                            # Simple linear projection based on current growth\n                            # This is a basic approximation - real world would use more sophisticated models\n                            if disk_usage_percent > 10:  # Only predict if there's meaningful usage\n                                # Assume 1% growth per month as baseline (adjustable)\n                                monthly_growth = 1.0\n                                predicted_usage = disk_usage_percent + (monthly_growth * projection_days / 30)\n                                \n                                disk_prediction = {\n                                    \"mount_point\": safe_get(disk, \"mnt_point\"),\n                                    \"current_usage_percent\": disk_usage_percent,\n                                    \"predicted_usage_percent\": min(predicted_usage, 100),\n                                    \"size_gb\": safe_get(disk, \"size\", 0) / (1024**3),\n                                    \"free_gb\": safe_get(disk, \"free\", 0) / (1024**3),\n                                    \"growth_rate_monthly\": monthly_growth,\n                                    \"days_to_90_percent\": _calculate_days_to_threshold(\n                                        disk_usage_percent, 90, monthly_growth / 30\n                                    ) if disk_usage_percent < 90 else None,\n                                    \"days_to_95_percent\": _calculate_days_to_threshold(\n                                        disk_usage_percent, 95, monthly_growth / 30\n                                    ) if disk_usage_percent < 95 else None\n                                }\n                                disk_predictions.append(disk_prediction)\n                    \n                    # Generate capacity recommendations\n                    recommendations = _generate_capacity_recommendations(\n                        current_utilization, resource_predictions, disk_predictions, projection_days\n                    )\n                    \n                    # Calculate resource adequacy scores\n                    adequacy_scores = _calculate_resource_adequacy(\n                        resource_predictions, projection_days\n                    )\n                    \n                    prediction_result = {\n                        \"server_alias\": alias,\n                        \"timestamp\": datetime.now().isoformat(),\n                        \"projection_parameters\": {\n                            \"projection_days\": projection_days,\n                            \"confidence_level\": confidence_level,\n                            \"end_date\": (datetime.now() + timedelta(days=projection_days)).isoformat()[:10]\n                        },\n                        \"current_utilization\": current_utilization,\n                        \"resource_predictions\": resource_predictions,\n                        \"disk_predictions\": disk_predictions,\n                        \"adequacy_scores\": adequacy_scores,\n                        \"recommendations\": recommendations,\n                        \"summary\": {\n                            \"overall_risk_level\": _assess_overall_capacity_risk(adequacy_scores),\n                            \"resources_at_risk\": len([r for r in adequacy_scores.values() if r.get(\"risk_level\") in [\"high\", \"critical\"]]),\n                            \"immediate_action_needed\": any(\n                                r.get(\"risk_level\") == \"critical\" for r in adequacy_scores.values()\n                            ),\n                            \"planning_horizon_days\": projection_days\n                        }\n                    }\n                    \n                    predictions[alias] = prediction_result\n                \n                except Exception as e:\n                    logger.warning(\n                        \"Error predicting resource needs for server\",\n                        server_alias=alias,\n                        error=str(e)\n                    )\n                    predictions[alias] = {\n                        \"server_alias\": alias,\n                        \"error\": str(e),\n                        \"timestamp\": datetime.now().isoformat()\n                    }\n            \n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"predict_resource_needs\", duration_ms, True)\n            \n            return {\"servers\": predictions}\n        \n        except Exception as e:\n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"predict_resource_needs\", duration_ms, False)\n            logger.error(\"Error in predict_resource_needs\", server_alias=server_alias, error=str(e))\n            raise\n    \n    @app.tool()\n    async def compare_servers(\n        server_aliases: Optional[List[str]] = None,\n        metrics: Optional[List[str]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Compare resource utilization and performance across servers.\"\"\"\n        start_time = datetime.now()\n        \n        try:\n            if metrics is None:\n                metrics = [\"cpu_usage\", \"memory_usage\", \"load_average\", \"disk_usage\"]\n            \n            clients = {}\n            if server_aliases:\n                for alias in server_aliases:\n                    if alias not in client_pool.servers:\n                        raise ValueError(f\"Server '{alias}' not found\")\n                    client = client_pool.get_client(alias)\n                    if client:\n                        clients[alias] = client\n            else:\n                clients = client_pool.get_enabled_clients()\n            \n            if len(clients) < 2:\n                return {\n                    \"error\": \"At least 2 servers required for comparison\",\n                    \"available_servers\": list(clients.keys())\n                }\n            \n            server_data = {}\n            \n            # Collect metrics from all servers\n            for alias, client in clients.items():\n                try:\n                    cpu_data = await client.get_cpu_info()\n                    memory_data = await client.get_memory_info()\n                    disk_data = await client.get_disk_usage()\n                    load_data = await client.get_load_average()\n                    system_data = await client.get_system_info()\n                    \n                    # Calculate aggregate disk usage\n                    disk_usages = [safe_get(disk, \"percent\", 0) for disk in disk_data]\n                    avg_disk_usage = sum(disk_usages) / len(disk_usages) if disk_usages else 0\n                    max_disk_usage = max(disk_usages) if disk_usages else 0\n                    \n                    server_metrics = {\n                        \"cpu_usage\": safe_get(cpu_data, \"total\", 0),\n                        \"memory_usage\": safe_get(memory_data, \"percent\", 0),\n                        \"load_average\": safe_get(load_data, \"min5\", 0),\n                        \"disk_usage_avg\": avg_disk_usage,\n                        \"disk_usage_max\": max_disk_usage,\n                        \"cpu_count\": safe_get(system_data, \"cpucount\", 1),\n                        \"memory_total_gb\": safe_get(memory_data, \"total\", 0) / (1024**3),\n                        \"load_normalized\": safe_get(load_data, \"min5\", 0) / safe_get(system_data, \"cpucount\", 1),\n                        \"server_config\": client_pool.servers[alias]\n                    }\n                    \n                    server_data[alias] = server_metrics\n                \n                except Exception as e:\n                    logger.warning(\n                        \"Error collecting metrics for server comparison\",\n                        server_alias=alias,\n                        error=str(e)\n                    )\n                    server_data[alias] = {\"error\": str(e)}\n            \n            # Perform comparisons\n            comparison_results = {}\n            \n            # Statistical analysis of each metric\n            metric_stats = {}\n            for metric in metrics:\n                if metric == \"disk_usage\":\n                    values = [data[\"disk_usage_max\"] for data in server_data.values() if \"error\" not in data]\n                else:\n                    values = [data.get(metric, 0) for data in server_data.values() if \"error\" not in data]\n                \n                if values:\n                    metric_stats[metric] = {\n                        \"min\": min(values),\n                        \"max\": max(values),\n                        \"avg\": sum(values) / len(values),\n                        \"range\": max(values) - min(values),\n                        \"std_dev\": _calculate_std_dev(values)\n                    }\n            \n            # Identify outliers and leaders\n            outliers = {}\n            leaders = {}\n            \n            for metric in metrics:\n                if metric in metric_stats:\n                    stats = metric_stats[metric]\n                    threshold = stats[\"avg\"] + (2 * stats[\"std_dev\"])  # 2 sigma\n                    \n                    # High outliers (concerning for most metrics)\n                    high_outliers = [\n                        alias for alias, data in server_data.items()\n                        if \"error\" not in data and data.get(metric == \"disk_usage\" and \"disk_usage_max\" or metric, 0) > threshold\n                    ]\n                    \n                    # Leaders (best performers)\n                    best_performers = sorted(\n                        [(alias, data) for alias, data in server_data.items() if \"error\" not in data],\n                        key=lambda x: x[1].get(metric == \"disk_usage\" and \"disk_usage_max\" or metric, 0)\n                    )[:3]\n                    \n                    if high_outliers:\n                        outliers[metric] = high_outliers\n                    \n                    leaders[metric] = [alias for alias, _ in best_performers]\n            \n            # Resource efficiency analysis\n            efficiency_scores = {}\n            for alias, data in server_data.items():\n                if \"error\" not in data:\n                    # Simple efficiency score (lower is better for utilization metrics)\n                    cpu_score = 100 - data[\"cpu_usage\"]\n                    memory_score = 100 - data[\"memory_usage\"]\n                    load_score = max(0, 100 - (data[\"load_normalized\"] * 100))\n                    disk_score = 100 - data[\"disk_usage_max\"]\n                    \n                    efficiency_scores[alias] = {\n                        \"cpu_efficiency\": cpu_score,\n                        \"memory_efficiency\": memory_score,\n                        \"load_efficiency\": load_score,\n                        \"disk_efficiency\": disk_score,\n                        \"overall_efficiency\": (cpu_score + memory_score + load_score + disk_score) / 4\n                    }\n            \n            # Environment and tag analysis\n            environment_analysis = _analyze_by_environment(server_data, client_pool)\n            tag_analysis = _analyze_by_tags(server_data, client_pool)\n            \n            comparison_result = {\n                \"timestamp\": datetime.now().isoformat(),\n                \"servers_compared\": len([s for s in server_data.values() if \"error\" not in s]),\n                \"servers_with_errors\": len([s for s in server_data.values() if \"error\" in s]),\n                \"metrics_analyzed\": metrics,\n                \"server_data\": server_data,\n                \"statistical_analysis\": metric_stats,\n                \"performance_leaders\": leaders,\n                \"outliers\": outliers,\n                \"efficiency_scores\": efficiency_scores,\n                \"environment_analysis\": environment_analysis,\n                \"tag_analysis\": tag_analysis,\n                \"recommendations\": _generate_comparison_recommendations(\n                    server_data, outliers, leaders, efficiency_scores\n                )\n            }\n            \n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"compare_servers\", duration_ms, True)\n            \n            return comparison_result\n        \n        except Exception as e:\n            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n            performance_logger.log_tool_execution(\"compare_servers\", duration_ms, False)\n            logger.error(\"Error in compare_servers\", server_aliases=server_aliases, error=str(e))\n            raise\n\n\ndef _predict_resource_growth(\n    current_value: float,\n    recent_change_percent: float,\n    projection_days: int,\n    resource_type: str\n) -> Dict[str, Any]:\n    \"\"\"Predict resource growth using linear trend.\"\"\"\n    # Convert weekly change to daily change\n    daily_change_percent = recent_change_percent / 7\n    \n    # Project future value\n    projected_change = daily_change_percent * projection_days\n    predicted_value = current_value + (current_value * projected_change / 100)\n    \n    # Apply reasonable bounds\n    if resource_type in [\"cpu_percent\", \"memory_percent\"]:\n        predicted_value = max(0, min(predicted_value, 100))\n    elif resource_type == \"load_average\":\n        predicted_value = max(0, predicted_value)\n    \n    return {\n        \"current_value\": current_value,\n        \"predicted_value\": predicted_value,\n        \"growth_amount\": predicted_value - current_value,\n        \"growth_percent\": ((predicted_value - current_value) / current_value * 100) if current_value > 0 else 0,\n        \"daily_change_percent\": daily_change_percent,\n        \"projection_days\": projection_days\n    }\n\n\ndef _calculate_days_to_threshold(current: float, threshold: float, daily_change: float) -> Optional[int]:\n    \"\"\"Calculate days to reach threshold.\"\"\"\n    if daily_change <= 0 or current >= threshold:\n        return None\n    \n    days = (threshold - current) / daily_change\n    return int(days) if days > 0 else None\n\n\ndef _generate_capacity_recommendations(\n    current: Dict[str, Any],\n    predictions: Dict[str, Dict[str, Any]],\n    disk_predictions: List[Dict[str, Any]],\n    projection_days: int\n) -> List[str]:\n    \"\"\"Generate capacity planning recommendations.\"\"\"\n    recommendations = []\n    \n    # CPU recommendations\n    if \"cpu\" in predictions:\n        cpu_pred = predictions[\"cpu\"]\n        if cpu_pred[\"predicted_value\"] > 90:\n            recommendations.append(\n                f\"Critical: CPU utilization predicted to reach {cpu_pred['predicted_value']:.1f}% \"\n                f\"in {projection_days} days. Plan CPU upgrade immediately.\"\n            )\n        elif cpu_pred[\"predicted_value\"] > 80:\n            recommendations.append(\n                f\"Warning: CPU utilization predicted to reach {cpu_pred['predicted_value']:.1f}% \"\n                f\"in {projection_days} days. Consider CPU upgrade planning.\"\n            )\n    \n    # Memory recommendations\n    if \"memory\" in predictions:\n        mem_pred = predictions[\"memory\"]\n        if mem_pred[\"predicted_value\"] > 90:\n            additional_gb = mem_pred[\"memory_growth_gb\"]\n            recommendations.append(\n                f\"Critical: Memory utilization predicted to reach {mem_pred['predicted_value']:.1f}% \"\n                f\"({additional_gb:.1f} GB additional) in {projection_days} days. Plan memory upgrade.\"\n            )\n        elif mem_pred[\"predicted_value\"] > 80:\n            recommendations.append(\n                f\"Warning: Memory utilization predicted to reach {mem_pred['predicted_value']:.1f}% \"\n                f\"in {projection_days} days. Monitor closely and plan for potential upgrade.\"\n            )\n    \n    # Load recommendations\n    if \"load\" in predictions:\n        load_pred = predictions[\"load\"]\n        if load_pred[\"normalized_predicted\"] > 2.0:\n            recommendations.append(\n                f\"Critical: System load predicted to reach {load_pred['predicted_value']:.1f} \"\n                f\"({load_pred['normalized_predicted']:.1f} per CPU) in {projection_days} days. \"\n                \"Performance will be severely impacted.\"\n            )\n        elif load_pred[\"normalized_predicted\"] > 1.5:\n            recommendations.append(\n                f\"Warning: System load predicted to reach {load_pred['predicted_value']:.1f} \"\n                f\"in {projection_days} days. Monitor for performance impact.\"\n            )\n    \n    # Disk recommendations\n    for disk_pred in disk_predictions:\n        if disk_pred.get(\"days_to_95_percent\") and disk_pred[\"days_to_95_percent\"] <= projection_days:\n            recommendations.append(\n                f\"Critical: {disk_pred['mount_point']} predicted to reach 95% capacity \"\n                f\"in {disk_pred['days_to_95_percent']} days. Plan disk expansion immediately.\"\n            )\n        elif disk_pred.get(\"days_to_90_percent\") and disk_pred[\"days_to_90_percent\"] <= projection_days:\n            recommendations.append(\n                f\"Warning: {disk_pred['mount_point']} predicted to reach 90% capacity \"\n                f\"in {disk_pred['days_to_90_percent']} days. Plan disk expansion.\"\n            )\n    \n    if not recommendations:\n        recommendations.append(\"No immediate capacity concerns identified for the projection period.\")\n    \n    return recommendations\n\n\ndef _calculate_resource_adequacy(predictions: Dict[str, Dict[str, Any]], projection_days: int) -> Dict[str, Any]:\n    \"\"\"Calculate adequacy scores for predicted resource utilization.\"\"\"\n    adequacy_scores = {}\n    \n    for resource, pred in predictions.items():\n        predicted_value = pred[\"predicted_value\"]\n        \n        if resource in [\"cpu\", \"memory\"]:\n            if predicted_value >= 95:\n                risk_level = \"critical\"\n                adequacy_score = 0\n            elif predicted_value >= 85:\n                risk_level = \"high\"\n                adequacy_score = 25\n            elif predicted_value >= 70:\n                risk_level = \"medium\"\n                adequacy_score = 50\n            elif predicted_value >= 50:\n                risk_level = \"low\"\n                adequacy_score = 75\n            else:\n                risk_level = \"minimal\"\n                adequacy_score = 100\n        \n        elif resource == \"load\":\n            normalized = predicted_value / pred.get(\"cpu_count\", 1)\n            if normalized >= 3.0:\n                risk_level = \"critical\"\n                adequacy_score = 0\n            elif normalized >= 2.0:\n                risk_level = \"high\"\n                adequacy_score = 25\n            elif normalized >= 1.5:\n                risk_level = \"medium\"\n                adequacy_score = 50\n            elif normalized >= 1.0:\n                risk_level = \"low\"\n                adequacy_score = 75\n            else:\n                risk_level = \"minimal\"\n                adequacy_score = 100\n        else:\n            # Default scoring for other resources\n            risk_level = \"unknown\"\n            adequacy_score = 50\n        \n        adequacy_scores[resource] = {\n            \"adequacy_score\": adequacy_score,\n            \"risk_level\": risk_level,\n            \"predicted_value\": predicted_value,\n            \"projection_days\": projection_days\n        }\n    \n    return adequacy_scores\n\n\ndef _assess_overall_capacity_risk(adequacy_scores: Dict[str, Any]) -> str:\n    \"\"\"Assess overall capacity risk level.\"\"\"\n    if not adequacy_scores:\n        return \"unknown\"\n    \n    risk_levels = [score[\"risk_level\"] for score in adequacy_scores.values()]\n    \n    if \"critical\" in risk_levels:\n        return \"critical\"\n    elif \"high\" in risk_levels:\n        return \"high\"\n    elif \"medium\" in risk_levels:\n        return \"medium\"\n    elif \"low\" in risk_levels:\n        return \"low\"\n    else:\n        return \"minimal\"\n\n\ndef _calculate_std_dev(values: List[float]) -> float:\n    \"\"\"Calculate standard deviation.\"\"\"\n    if len(values) < 2:\n        return 0.0\n    \n    mean = sum(values) / len(values)\n    variance = sum((x - mean) ** 2 for x in values) / (len(values) - 1)\n    return variance ** 0.5\n\n\ndef _analyze_by_environment(server_data: Dict[str, Any], client_pool: GlancesClientPool) -> Dict[str, Any]:\n    \"\"\"Analyze server performance by environment.\"\"\"\n    env_analysis = {}\n    \n    for alias, data in server_data.items():\n        if \"error\" in data:\n            continue\n        \n        server_config = client_pool.servers.get(alias)\n        if not server_config or not server_config.environment:\n            continue\n        \n        env = server_config.environment.value\n        if env not in env_analysis:\n            env_analysis[env] = {\n                \"servers\": [],\n                \"avg_cpu\": 0,\n                \"avg_memory\": 0,\n                \"avg_load\": 0\n            }\n        \n        env_analysis[env][\"servers\"].append(alias)\n        env_analysis[env][\"avg_cpu\"] += data.get(\"cpu_usage\", 0)\n        env_analysis[env][\"avg_memory\"] += data.get(\"memory_usage\", 0)\n        env_analysis[env][\"avg_load\"] += data.get(\"load_normalized\", 0)\n    \n    # Calculate averages\n    for env, data in env_analysis.items():\n        server_count = len(data[\"servers\"])\n        if server_count > 0:\n            data[\"avg_cpu\"] /= server_count\n            data[\"avg_memory\"] /= server_count\n            data[\"avg_load\"] /= server_count\n            data[\"server_count\"] = server_count\n    \n    return env_analysis\n\n\ndef _analyze_by_tags(server_data: Dict[str, Any], client_pool: GlancesClientPool) -> Dict[str, Any]:\n    \"\"\"Analyze server performance by tags.\"\"\"\n    tag_analysis = {}\n    \n    for alias, data in server_data.items():\n        if \"error\" in data:\n            continue\n        \n        server_config = client_pool.servers.get(alias)\n        if not server_config or not server_config.tags:\n            continue\n        \n        for tag in server_config.tags:\n            if tag not in tag_analysis:\n                tag_analysis[tag] = {\n                    \"servers\": [],\n                    \"avg_cpu\": 0,\n                    \"avg_memory\": 0,\n                    \"avg_load\": 0\n                }\n            \n            tag_analysis[tag][\"servers\"].append(alias)\n            tag_analysis[tag][\"avg_cpu\"] += data.get(\"cpu_usage\", 0)\n            tag_analysis[tag][\"avg_memory\"] += data.get(\"memory_usage\", 0)\n            tag_analysis[tag][\"avg_load\"] += data.get(\"load_normalized\", 0)\n    \n    # Calculate averages\n    for tag, data in tag_analysis.items():\n        server_count = len(data[\"servers\"])\n        if server_count > 0:\n            data[\"avg_cpu\"] /= server_count\n            data[\"avg_memory\"] /= server_count\n            data[\"avg_load\"] /= server_count\n            data[\"server_count\"] = server_count\n    \n    return tag_analysis\n\n\ndef _generate_comparison_recommendations(\n    server_data: Dict[str, Any],\n    outliers: Dict[str, List[str]],\n    leaders: Dict[str, List[str]],\n    efficiency_scores: Dict[str, Any]\n) -> List[str]:\n    \"\"\"Generate recommendations based on server comparison.\"\"\"\n    recommendations = []\n    \n    # Outlier recommendations\n    for metric, outlier_servers in outliers.items():\n        if outlier_servers:\n            recommendations.append(\n                f\"High {metric.replace('_', ' ')} detected on servers: {', '.join(outlier_servers)}. \"\n                \"Investigate resource constraints or workload distribution.\"\n            )\n    \n    # Efficiency recommendations\n    if efficiency_scores:\n        worst_performers = sorted(\n            efficiency_scores.items(),\n            key=lambda x: x[1][\"overall_efficiency\"]\n        )[:3]\n        \n        if worst_performers and worst_performers[0][1][\"overall_efficiency\"] < 50:\n            worst_server = worst_performers[0][0]\n            recommendations.append(\n                f\"Server {worst_server} has low overall efficiency ({worst_performers[0][1]['overall_efficiency']:.1f}%). \"\n                \"Consider workload redistribution or resource optimization.\"\n            )\n    \n    # Load balancing recommendations\n    cpu_values = [(alias, data.get(\"cpu_usage\", 0)) for alias, data in server_data.items() if \"error\" not in data]\n    if cpu_values and len(cpu_values) > 1:\n        cpu_values.sort(key=lambda x: x[1])\n        lowest_cpu = cpu_values[0]\n        highest_cpu = cpu_values[-1]\n        \n        if highest_cpu[1] - lowest_cpu[1] > 30:  # More than 30% difference\n            recommendations.append(\n                f\"Significant CPU usage imbalance detected. Consider redistributing workload \"\n                f\"from {highest_cpu[0]} ({highest_cpu[1]:.1f}%) to {lowest_cpu[0]} ({lowest_cpu[1]:.1f}%).\"\n            )\n    \n    if not recommendations:\n        recommendations.append(\"Server resource utilization appears well-balanced across the fleet.\")\n    \n    return recommendations